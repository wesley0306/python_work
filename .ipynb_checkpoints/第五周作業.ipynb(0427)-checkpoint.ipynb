{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDb 是一個 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shapes():\n",
    "    print(\"x_train: {}\".format(x_train.shape))\n",
    "    print(\"x_test:  {}\".format(x_test.shape)) \n",
    "    print(\"y_train: {}\".format(y_train.shape))\n",
    "    print(\"y_test:  {}\".format(y_test.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lens():\n",
    "    print(\"x_train: {}\".format(len(x_train)))\n",
    "    print(\"x_test:  {}\".format(len(x_test)) )\n",
    "    print(\"y_train: {}\".format(len(y_train)))\n",
    "    print(\"y_test:  {}\".format(len(y_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_type():\n",
    "    print(\"x_train: {}\".format(type(x_train)))\n",
    "    print(\"x_test:  {}\".format(type(x_test)) )\n",
    "    print(\"y_train: {}\".format(type(y_train)))\n",
    "    print(\"y_test:  {}\".format(type(y_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (25000,)\n",
      "x_test:  (25000,)\n",
      "y_train: (25000,)\n",
      "y_test:  (25000,)\n",
      "x_train: 25000\n",
      "x_test:  25000\n",
      "y_train: 25000\n",
      "y_test:  25000\n",
      "x_train: <class 'numpy.ndarray'>\n",
      "x_test:  <class 'numpy.ndarray'>\n",
      "y_train: <class 'numpy.ndarray'>\n",
      "y_test:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "show_shapes()\n",
    "show_lens()\n",
    "show_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN网络容易出现反向传播过程中的梯度问题。主要原因是我们通常给RNN的参数为有限的序列。\n",
    "\n",
    "#为了实现的简便，keras只能接受长度相同的序列输入。因此如果目前序列长度参差不齐，这时需要使用pad_sequences()。该函数是将序列转化为经过填充以后的一个新序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)\n",
    "# maxlen: 整数，所有序列的最大长度。长于该长度的序列将会截短，短于该长度的序列将会填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: <class 'numpy.ndarray'>\n",
      "x_test:  <class 'numpy.ndarray'>\n",
      "y_train: <class 'numpy.ndarray'>\n",
      "y_test:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "show_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(10000, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.LSTM = long short term memory，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。 简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.dropout: 在 0 和 1 之间的浮点数。 单元的丢弃比例，用于输入的线性转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.recurrent_dropout: 在 0 和 1 之间的浮点数。 单元的丢弃比例，            用于循环层状态的线性转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,411,713\n",
      "Trainable params: 1,411,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 369s 15ms/sample - loss: 0.4552 - accuracy: 0.7869 - val_loss: 0.4116 - val_accuracy: 0.8218\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 336s 13ms/sample - loss: 0.3122 - accuracy: 0.8707 - val_loss: 0.3897 - val_accuracy: 0.8415\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 336s 13ms/sample - loss: 0.2452 - accuracy: 0.9010 - val_loss: 0.3697 - val_accuracy: 0.8436\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 336s 13ms/sample - loss: 0.1945 - accuracy: 0.9259 - val_loss: 0.4088 - val_accuracy: 0.8374\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 348s 14ms/sample - loss: 0.1577 - accuracy: 0.9426 - val_loss: 0.4220 - val_accuracy: 0.8402\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 336s 13ms/sample - loss: 0.1269 - accuracy: 0.9546 - val_loss: 0.4741 - val_accuracy: 0.8350\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 336s 13ms/sample - loss: 0.0982 - accuracy: 0.9642 - val_loss: 0.5450 - val_accuracy: 0.8350\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 336s 13ms/sample - loss: 0.0855 - accuracy: 0.9706 - val_loss: 0.6162 - val_accuracy: 0.8329\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 338s 14ms/sample - loss: 0.0609 - accuracy: 0.9790 - val_loss: 0.6577 - val_accuracy: 0.8310\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 343s 14ms/sample - loss: 0.0488 - accuracy: 0.9847 - val_loss: 0.7541 - val_accuracy: 0.8326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1da0620b848>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10,\n",
    "         validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### y_test:  (25000,) 與 (25000,1) 的區別，以及適用時機，都能丟進fit嗎?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON(JavaScript Object Notation) 是一種輕量級的數據交換格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('imdb_model_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('imdb_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
